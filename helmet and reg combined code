import cv2
import numpy as np
import firebase_admin
from firebase_admin import credentials, db

# Initialize Firebase Realtime Database
cred = credentials.Certificate('fire-836b7-firebase-adminsdk-o14a6-b5aaf1ddc1.json')
firebase_admin.initialize_app(cred, {"databaseURL": "https://fire-836b7-default-rtdb.firebaseio.com/"})
db_helmet_ref = db.reference("/helmet_detection")
db_object_ref = db.reference("/object_detection")

# Load YOLOv3 model for helmet detection
helmet_net = cv2.dnn.readNet('yolov3-helmet.weights', 'yolov3-helmet.cfg')
helmet_classes = []
with open('helmet.names', 'r') as f:
    helmet_classes = [line.strip() for line in f]

# Load YOLOv3 model for object detection (assuming person detection)
object_net = cv2.dnn.readNet('yolov3.weights', 'yolov3.cfg')
object_classes = []
with open('coco.names', 'r') as f:
    object_classes = [line.strip() for line in f]

# Set up webcam
cap = cv2.VideoCapture(0)

# Non-maximum suppression parameters
nms_threshold = 0.5

while True:
    ret, frame = cap.read()

    if not ret:
        print("Error: Failed to capture image.")
        break

    height, width, _ = frame.shape

    # Detect helmets
    helmet_blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    helmet_net.setInput(helmet_blob)
    helmet_output_layers = helmet_net.getUnconnectedOutLayersNames()
    helmet_detections = helmet_net.forward(helmet_output_layers)

    helmet_boxes = []
    helmet_confidences = []

    for detection in helmet_detections:
        for obj in detection:
            scores = obj[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            if class_id == 0 and confidence > 0.8:
                center_x, center_y, w, h = (obj[0:4] * np.array([width, height, width, height])).astype("int")
                x, y = int(center_x - w / 2), int(center_y - h / 2)

                helmet_boxes.append([x, y, w, h])
                helmet_confidences.append(float(confidence))

    helmet_indices = cv2.dnn.NMSBoxes(helmet_boxes, helmet_confidences, 0.5, nms_threshold)

    helmet_detected = False
    if len(helmet_indices) > 0:
        helmet_detected = True
        for i in helmet_indices.flatten():
            x, y, w, h = helmet_boxes[i]
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            cv2.putText(frame, 'Helmet Detected', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

    # Detect people (assuming they are objects like water bottles)
    object_blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
    object_net.setInput(object_blob)
    object_output_layers = object_net.getUnconnectedOutLayersNames()
    object_detections = object_net.forward(object_output_layers)

    object_boxes = []
    object_confidences = []

    for detection in object_detections:
        for obj in detection:
            scores = obj[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]

            if confidence > 0.5 and object_classes[class_id] == 'person':
                center_x, center_y, w, h = (obj[0:4] * np.array([width, height, width, height])).astype("int")
                x, y = int(center_x - w / 2), int(center_y - h / 2)

                object_boxes.append([x, y, w, h])
                object_confidences.append(float(confidence))

    object_indices = cv2.dnn.NMSBoxes(object_boxes, object_confidences, 0.5, nms_threshold)

    object_detected = False
    if len(object_indices) > 0:
        object_detected = True
        for i in object_indices.flatten():
            x, y, w, h = object_boxes[i]
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 255), 2)
            cv2.putText(frame, 'Person Detected', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 255), 2)

    # Display the result on the frame
    if not helmet_detected:
        cv2.putText(frame, 'No Helmet Detected', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
    if not object_detected:
        cv2.putText(frame, 'No Person Detected', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)

    cv2.imshow('Detection Feed', frame)

    # Store the boolean values in Firebase Realtime Database
    db_helmet_ref.set({'helmet_detected': helmet_detected})
    db_object_ref.set({'object_detected': object_detected})

    # Break the loop if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the webcam and close all windows
cap.release()
cv2.destroyAllWindows()
